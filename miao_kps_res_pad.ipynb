{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T16:59:31.069432Z",
     "start_time": "2019-12-28T16:59:30.403635Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageDraw \n",
    "import itertools\n",
    "import random\n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T16:59:32.788624Z",
     "start_time": "2019-12-28T16:59:32.785557Z"
    }
   },
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    line_parts = line.tolist()\n",
    "    img_name = line_parts[0]\n",
    "    landmarks = list(map(int, line_parts[1: len(line_parts)]))\n",
    "    return img_name, landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T16:59:33.023047Z",
     "start_time": "2019-12-28T16:59:32.984214Z"
    }
   },
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \"\"\"\n",
    "        Resieze to train_boarder x train_boarder. Here we use 224 x 224\n",
    "        Then do channel normalization: (image - mean) / std_variation\n",
    "    \"\"\"\n",
    "    def __init__(self,train_boarder= 224):\n",
    "        self.train_boarder = train_boarder\n",
    "    def __call__(self,sample):\n",
    "        img, landmarks = sample['image'], sample['landmarks']\n",
    "        w = img.width\n",
    "        h = img.height\n",
    "        img_pad = np.zeros((max(w,h),max(w,h),3),dtype= 'uint8')\n",
    "        img_pad[:h,:w,:] = np.asarray(img,dtype= 'uint8')\n",
    "        img_resize = np.asarray(Image.fromarray(img_pad).resize((self.train_boarder, self.train_boarder),Image.BILINEAR))\n",
    "        landmarks *= 224/max(w,h) \n",
    "        return {'image':img_resize,'landmarks':landmarks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T16:59:33.192114Z",
     "start_time": "2019-12-28T16:59:33.187419Z"
    }
   },
   "outputs": [],
   "source": [
    "class FlipHorizontal(object):\n",
    "    '''\n",
    "    flip horizontal\n",
    "    '''\n",
    "    def __init__(self,p= 0.5, train_boarder= 224):\n",
    "        self.p = p\n",
    "        self.train_boarder = train_boarder\n",
    "    def __call__(self,sample):\n",
    "        img, landmask = sample['image'], sample['landmarks']\n",
    "        if random.random() < self.p:\n",
    "            img = img[:,::-1].copy()\n",
    "            landmask[0::2] = self.train_boarder - landmask[0::2].copy()\n",
    "        return {'image':img,'landmarks':landmask}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T16:59:33.355469Z",
     "start_time": "2019-12-28T16:59:33.348509Z"
    }
   },
   "outputs": [],
   "source": [
    "class RandomRotation(object):\n",
    "    '''\n",
    "    RandomRotation(0,15)\n",
    "    '''\n",
    "    def __init__(self, train_boarder= 224, p= 0.5):\n",
    "        self.train_boarder = train_boarder\n",
    "        self.p = p\n",
    "    def __call__(self,sample):\n",
    "        img, landmask = sample['image'], sample['landmarks']\n",
    "        if random.random() < self.p:\n",
    "            ang = random.randint(-5, 5)\n",
    "            scale = 1.0\n",
    "            M = cv2.getRotationMatrix2D((self.train_boarder/2, self.train_boarder/2), ang, scale)\n",
    "            img = cv2.warpAffine(img, M, (self.train_boarder,self.train_boarder), flags= cv2.INTER_LINEAR)\n",
    "            xs = landmask[::2].copy()\n",
    "            ys = landmask[1::2].copy()\n",
    "        \n",
    "            #opencv获得的旋转矩阵是调整过的，需要注意\n",
    "            mxy = (np.c_[xs,ys] - np.array([self.train_boarder/2, self.train_boarder/2])) \n",
    "            xys = (mxy.dot( np.transpose( M[:,:2] ) ) + np.array([self.train_boarder/2, self.train_boarder/2]))\n",
    "        \n",
    "            landmask[::2] = xys[:,0]\n",
    "            landmask[1::2] = xys[:,1]\n",
    "        return {'image':img,'landmarks':landmask}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T16:59:33.502470Z",
     "start_time": "2019-12-28T16:59:33.499003Z"
    }
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "        Convert ndarrays in sample to Tensors.\n",
    "        Tensors channel sequence: N x C x H x W\n",
    "    \"\"\"\n",
    "    def __call__(self,sample):\n",
    "        '''\n",
    "        numpy img: H*W*C\n",
    "        torch.tensorimg: N*C*H*W\n",
    "        '''\n",
    "        img, landmarks = sample['image'], sample['landmarks']\n",
    "#         如果不是灰度图要改变维度\n",
    "        img = img.transpose((2, 0, 1))\n",
    "#         img = np.expand_dims(img, axis=0)\n",
    "        return {'image':torch.from_numpy(img).float(), \n",
    "                'landmarks':torch.from_numpy(landmarks).float()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T16:59:33.707501Z",
     "start_time": "2019-12-28T16:59:33.703107Z"
    }
   },
   "outputs": [],
   "source": [
    "class FaceLandmarksDataset():\n",
    "    def __init__(self, data, transforms= None, train_boarder= 224):\n",
    "        '''\n",
    "        :param lines: src_line\n",
    "        :param transform: data transform\n",
    "        '''\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "        self.train_boarder = train_boarder\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img, landmarks = parse_line(self.data.values[idx])\n",
    "        #打开图片\n",
    "        img = Image.open(img)\n",
    "        landmarks = np.array(landmarks).astype('float64')\n",
    "        sample = {'image':img, 'landmarks':landmarks}\n",
    "        sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T17:20:43.950078Z",
     "start_time": "2019-12-28T17:20:43.945450Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(filepath, phase):\n",
    "    '''\n",
    "    加载数据\n",
    "    '''\n",
    "    df = pd.read_csv(filepath)\n",
    "    if phase == 'Train' or phase == 'train':\n",
    "        tsfm = transforms.Compose([\n",
    "            Normalize(),                # do channel normalization\n",
    "#             FlipHorizontal(),           # do Flip Horizontal\n",
    "#             RandomRotation(),           # do Random Rotation\n",
    "            ToTensor()]                 # convert to torch type: NxCxHxW\n",
    "        )\n",
    "    else:\n",
    "        tsfm = transforms.Compose([\n",
    "            Normalize(),\n",
    "            ToTensor()]\n",
    "        )\n",
    "    data_set = FaceLandmarksDataset(df, transforms= tsfm)\n",
    "    return data_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T17:20:47.436596Z",
     "start_time": "2019-12-28T17:20:47.433496Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_test_set():\n",
    "    train_set = load_data('data/train_annotation.csv','train')\n",
    "    valid_set = load_data('data/test_annotation.csv','test')\n",
    "    return train_set, valid_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T17:20:48.327346Z",
     "start_time": "2019-12-28T17:20:48.322793Z"
    }
   },
   "outputs": [],
   "source": [
    "def drawLandMarks(path, idx):\n",
    "    '''\n",
    "    在resize后的图上画出landmarks\n",
    "    '''\n",
    "    dataset = load_data(path, 'train')\n",
    "    \n",
    "    sample = dataset[idx]\n",
    "    img = sample['image'].type(torch.uint8).numpy().transpose((1,2,0))\n",
    "    landmarks = sample['landmarks'].numpy()\n",
    "    xs = landmarks[::2]\n",
    "    ys = landmarks[1::2]\n",
    "    plt.imshow(img)\n",
    "    plt.scatter(xs,ys,c= 'r', edgecolors= 'r', s= 5)\n",
    "    plt.show()\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T17:20:54.562678Z",
     "start_time": "2019-12-28T17:20:54.051749Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    path= 'data/train_annotation.csv'\n",
    "    img = drawLandMarks(path= path, idx= 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T17:19:57.539748Z",
     "start_time": "2019-12-28T17:19:57.534570Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "class Net_res(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        初始化一些层，使用resnet18作为backbone\n",
    "        backbone最后一层输出改变成18\n",
    "        '''\n",
    "        super(Net_res,self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained= True)\n",
    "        self.resnet18.fc = torch.nn.Linear(in_features=512, out_features= 256, bias= True)\n",
    "        self.last_fc = torch.nn.Linear(256, 18, bias= True)\n",
    "        self.prelu = torch.nn.PReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        传播过程\n",
    "        '''\n",
    "        #输入尺寸为224*224\n",
    "        x = self.resnet18(x)\n",
    "        x = self.prelu(x)\n",
    "        x = self.last_fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T17:19:58.080418Z",
     "start_time": "2019-12-28T17:19:58.077662Z"
    }
   },
   "outputs": [],
   "source": [
    "def model_parameters_init(model):\n",
    "    '''\n",
    "    kaiming init\n",
    "    '''\n",
    "    for p in model.parameters():\n",
    "        if len(p.shape) >= 2:\n",
    "            nn.init.kaiming_normal_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T17:19:58.438478Z",
     "start_time": "2019-12-28T17:19:58.427525Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(args, train_loader, valid_loader, model, criterion, optimizer, scheduler, device):\n",
    "    #save model or not\n",
    "    if args.save_model:\n",
    "        if not os.path.exists(args.save_directory):\n",
    "            os.makedirs(args.save_directory)\n",
    "    \n",
    "    epochs = args.epochs\n",
    "    pts_criterion = criterion\n",
    "    \n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch_id in range(epochs):\n",
    "        #monitor training loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model.train()\n",
    "        ######################\n",
    "        #training the model#\n",
    "        ######################\n",
    "        train_batch_cnt = 0\n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            train_batch_cnt += 1\n",
    "            img = batch['image']\n",
    "            landmarks = batch['landmarks']\n",
    "            \n",
    "            # groundtruth\n",
    "            input_img = img.to(device)\n",
    "            target_pts = landmarks.to(device)\n",
    "            \n",
    "            #clear the gradients of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #get out_put\n",
    "            #print(input_img.dtype)\n",
    "            output_pts = model(input_img)\n",
    "            \n",
    "            #get loss\n",
    "            loss = pts_criterion(output_pts, target_pts)\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            #do bp\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #show log info\n",
    "            if batch_idx % args.log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]  pts_loss: {:.6f}'.format(\n",
    "                        epoch_id,\n",
    "                        batch_idx * len(img),\n",
    "                        len(train_loader.dataset),\n",
    "                        100. * batch_idx / len(train_loader),\n",
    "                        loss.item(),\n",
    "                        end= '')\n",
    "                      )\n",
    "        #记录train_loss\n",
    "        train_loss /= train_batch_cnt\n",
    "        train_losses.append(train_loss)\n",
    "            \n",
    "        ######################\n",
    "        # validate the model #\n",
    "        ######################\n",
    "        valid_loss = 0.0\n",
    "        #change model mode to eval ,not use BN/Dropout\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_batch_cnt = 0\n",
    "            \n",
    "            for valid_batch_idx, batch in enumerate(valid_loader):\n",
    "                valid_batch_cnt += 1\n",
    "                valid_img = batch['image']\n",
    "                landmarks = batch['landmarks']\n",
    "                \n",
    "                input_img = valid_img.to(device)\n",
    "                target_pts = landmarks.to(device)\n",
    "                \n",
    "                output_pts = model(input_img)\n",
    "                \n",
    "                valid_loss_batch = pts_criterion(output_pts, target_pts)\n",
    "                valid_loss += valid_loss_batch.item()\n",
    "            \n",
    "            valid_loss /= valid_batch_cnt * 1.0\n",
    "            #记录valid_loss\n",
    "            valid_losses.append(valid_loss)\n",
    "            print('Valid: pts_loss: {:.6f}'.format(valid_loss))\n",
    "            #学习率衰减\n",
    "            scheduler.step()\n",
    "        print('===========================================================')\n",
    "        #save model\n",
    "        if args.save_model and epoch_id % 10 == 0:\n",
    "            saved_model_name = os.path.join(args.save_directory, 'detector_epoch' + '_' + str(epoch_id) + '.pt')\n",
    "            torch.save(model.state_dict(), saved_model_name)\n",
    "    return train_losses, valid_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T18:37:19.717767Z",
     "start_time": "2019-12-28T18:37:19.693009Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Detector')\n",
    "    parser.add_argument('--batch_size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 256)')\n",
    "    parser.add_argument('--test_batch_size', type=int, default=256, metavar='N',\n",
    "                        help='input batch size for testing (default: 256)')\n",
    "    parser.add_argument('--predict_batch_size', type=int, default=1, metavar='N',\n",
    "                        help='input batch size for predict (default: 1)')\n",
    "    parser.add_argument('--epochs', type=int, default=50, metavar='N',\n",
    "                        help='number of epochs to train (default: 100)')\n",
    "    parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
    "                        help='learning rate (default: 0.001)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                        help='SGD momentum (default: 0.5)')\n",
    "    parser.add_argument('--cuda', action='store_true', default=False,\n",
    "                        help='enables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=10, metavar='S',\n",
    "                        help='random seed (default: 10)')\n",
    "    parser.add_argument('--log_interval', type=int, default=10, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--save_model', action='store_true', default=False,\n",
    "                        help='save the current Model')\n",
    "    parser.add_argument('--save_directory', type=str, default='trained_models',\n",
    "                        help='learnt models are saving here')\n",
    "    parser.add_argument('--phase', type=str, default='Train',   # Train/train, Predict/predict, Finetune/finetune\n",
    "                        help='training, predicting or finetuning')\n",
    "    args = parser.parse_args(['--batch_size=64',\n",
    "                              '--test_batch_size=64',\n",
    "                              '--predict_batch_size=1',\n",
    "                              '--epochs=11',\n",
    "                              '--lr=0.000001',\n",
    "                              '--momentum=0.5',\n",
    "                              '--cuda',\n",
    "                              '--seed=1',\n",
    "                              '--log_interval=10',\n",
    "                              '--save_model',\n",
    "                              '--save_directory=trained_models_res_pad',\n",
    "                              '--phase=finetune'])\n",
    "    ##############################################################################################################\n",
    "    #设置随机种子\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    #设置CPU/GPU\n",
    "    use_cuda = args.cuda and torch.cuda.is_available()\n",
    "    device = torch.device('cuda' if use_cuda else 'cpu')\n",
    "    #For multi GPUs, nothing need to change here\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    ###############################################################################################################\n",
    "    print('===> Loading Datasets')\n",
    "    train_set, test_set = get_train_test_set()\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=args.batch_size, shuffle=True, num_workers= 8, pin_memory= True)\n",
    "    valid_loader = torch.utils.data.DataLoader(test_set, batch_size=args.test_batch_size, num_workers= 8, pin_memory= True)\n",
    "    predict_loader = torch.utils.data.DataLoader(test_set, batch_size=args.predict_batch_size, num_workers= 1, pin_memory= False)\n",
    "    ###############################################################################################################\n",
    "    print('===> Building Model')\n",
    "    # For single GPU\n",
    "    print('===> runing on {}'.format(device))\n",
    "    ###############################################################################################################\n",
    "    print('===> init model')\n",
    "    model = Net_res()\n",
    "#     model = model_parameters_init(model)\n",
    "#     for param in model.parameters():\n",
    "#         param.requires_grad = False\n",
    "#     for param in model.resnet18.fc.parameters():\n",
    "#         param.requires_grad = True\n",
    "    ###############################################################################################################\n",
    "    model.to(device)\n",
    "    criterion_pts = nn.SmoothL1Loss()\n",
    "#     criterion_pts = nn.MSELoss()\n",
    "#     optimizer = optim.Adam(model.parameters(), lr= args.lr)\n",
    "    optimizer = optim.SGD(model.parameters(), lr = args.lr, momentum= args.momentum)\n",
    "    #学习率衰减\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, 5 , 0.9)\n",
    "    ###############################################################################################################\n",
    "    if args.phase == 'Train' or args.phase == 'train':\n",
    "        print('===> Start Training')\n",
    "        train_losses, valid_losses = train(args, train_loader, valid_loader, model, criterion_pts, optimizer, scheduler, device)\n",
    "        print('===> Done!')\n",
    "        return train_losses, valid_losses\n",
    "        \n",
    "    elif args.phase == 'Test' or args.phase == 'test':\n",
    "        print('===> Test')\n",
    "        path_model = os.path.join(args.save_directory, 'detector_epoch' + '_' + str(100) + '.pt')\n",
    "        model.load_state_dict(torch.load(path_model))\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_batch_cnt = 0\n",
    "            valid_loss = 0\n",
    "            for valid_batch_idx, batch in enumerate(valid_loader):\n",
    "                valid_batch_cnt += 1\n",
    "                valid_img = batch['image']\n",
    "                landmarks = batch['landmarks']\n",
    "                \n",
    "                input_img = valid_img.to(device)\n",
    "                target_pts = landmarks.to(device)\n",
    "#                 print(input_img.shape)\n",
    "                output_pts = model(input_img)\n",
    "#                 print(type(output_pts))\n",
    "                \n",
    "                valid_loss_batch = criterion_pts(output_pts, target_pts)\n",
    "                valid_loss += valid_loss_batch.item()\n",
    "            \n",
    "            valid_loss /= valid_batch_cnt * 1.0\n",
    "            print('Valid: pts_loss: {:.6f}'.format(valid_loss))\n",
    "        print('===> Done!')\n",
    "        return None, None\n",
    "        \n",
    "    elif args.phase == 'Finetune' or args.phase == 'finetune':\n",
    "        print('===> Finetune')\n",
    "        path_model = os.path.join(args.save_directory, 'detector_epoch' + '_' + str(100) + '.pt')\n",
    "        model.load_state_dict(torch.load(path_model))\n",
    "        model = model.to(device)\n",
    "        train_losses, valid_losses = train(args, train_loader, valid_loader, model, criterion_pts, optimizer, scheduler, device)\n",
    "        print('===> Done!')\n",
    "        return train_losses, valid_losses\n",
    "        \n",
    "    elif args.phase == 'Predict' or args.phase == 'predict':\n",
    "        print('===> Predict')\n",
    "        path_model = os.path.join(args.save_directory, 'detector_epoch' + '_' + str(100) + '.pt')\n",
    "        model.load_state_dict(torch.load(path_model))\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        idx = 12\n",
    "        with torch.no_grad():\n",
    "            for i,data in enumerate(predict_loader):\n",
    "                if i == idx:\n",
    "                    img = data['image'].to(device)\n",
    "                    output_pts = model(img)\n",
    "                    landmarks = output_pts[0].cpu().numpy()\n",
    "                    xs = landmarks[::2]\n",
    "                    ys = landmarks[1::2]\n",
    "                    img = transforms.ToPILImage()(img[0].cpu().type(torch.uint8))\n",
    "                    draw = ImageDraw.Draw(img)\n",
    "                    draw.point(list(zip(xs,ys)),fill = (255))\n",
    "                    plt.imshow(img)\n",
    "                    plt.show()\n",
    "                elif i > idx:\n",
    "                    break\n",
    "        print('===> Done!')\n",
    "        return list(zip(xs,ys)), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T18:40:02.324748Z",
     "start_time": "2019-12-28T18:37:26.411848Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    np.random.seed(1)\n",
    "    start = time.time()\n",
    "    train_losses, valid_losses = main()\n",
    "    end = time.time()\n",
    "    print('耗时：{}s'.format(end - start))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    np.random.seed(1)\n",
    "    start = time.time()\n",
    "    train_losses_1, valid_losses_1 = main()\n",
    "    end = time.time()\n",
    "    print('耗时：{}s'.format(end - start))\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses.extend(train_losses_1)\n",
    "valid_losses.extend(valid_losses_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T18:35:32.500506Z",
     "start_time": "2019-12-28T18:35:32.267024Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    plt.figure(0,(8,6))\n",
    "    start = 0\n",
    "    end = len(train_losses)\n",
    "    losses_train = train_losses[start:end]\n",
    "    losses_valid = valid_losses[start:end]\n",
    "    plt.plot(np.arange(len(losses_train)),losses_train)\n",
    "    plt.plot(np.arange(len(losses_valid)),losses_valid)\n",
    "    plt.legend(['train_losses','valid_losses'])\n",
    "    plt.title('valid_loss:{}'.format(round(losses_valid[-1],2)), fontsize = 15,pad= 15)\n",
    "#     plt.xlim(8,100)\n",
    "    plt.xlabel('epochs',fontsize = 15)\n",
    "    plt.ylabel('loss',fontsize = 15)\n",
    "    plt.savefig('figure/{}_Resnet_pad_50-150.jpg'.format(round(losses_valid[-1],2)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T18:40:24.150877Z",
     "start_time": "2019-12-28T18:40:24.147162Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T18:40:34.601275Z",
     "start_time": "2019-12-28T18:40:34.597637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8290041856"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.max_memory_cached(device= 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T18:41:36.021132Z",
     "start_time": "2019-12-28T18:41:36.018601Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T18:41:08.463981Z",
     "start_time": "2019-12-28T18:41:08.460428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla P40'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T18:41:10.415219Z",
     "start_time": "2019-12-28T18:41:10.412133Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
