{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageDraw \n",
    "import argparse\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "class Net_res(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        初始化一些层，使用resnet18作为backbone\n",
    "        backbone最后一层输出改变成18\n",
    "        '''\n",
    "        super(Net_res,self).__init__()\n",
    "        self.resnet18 = models.resnet18(pretrained= True)\n",
    "        self.resnet18.fc = torch.nn.Linear(in_features=512, out_features= 256, bias= True)\n",
    "        self.last_fc = torch.nn.Linear(256, 18, bias= True)\n",
    "        self.prelu = torch.nn.PReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        传播过程\n",
    "        '''\n",
    "        #输入尺寸为224*224\n",
    "        x = self.resnet18(x)\n",
    "        x = self.prelu(x)\n",
    "        x = self.last_fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(object):\n",
    "    \"\"\"\n",
    "        Resieze to train_boarder x train_boarder. Here we use 224 x 224\n",
    "        Then do channel normalization: (image - mean) / std_variation\n",
    "    \"\"\"\n",
    "    def __init__(self,train_boarder= 224):\n",
    "        self.train_boarder = train_boarder\n",
    "    def __call__(self,sample):\n",
    "        img, w, h = sample['image'], sample['w'], sample['h']\n",
    "        img_resize = np.asarray(img.resize((self.train_boarder, self.train_boarder),Image.BILINEAR))\n",
    "        return {'image':img_resize, 'image_ori':np.asarray(img), 'w' : w, 'h' : h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"\n",
    "        Convert ndarrays in sample to Tensors.\n",
    "        Tensors channel sequence: N x C x H x W\n",
    "    \"\"\"\n",
    "    def __call__(self,sample):\n",
    "        '''\n",
    "        numpy img: H*W*C\n",
    "        torch.tensorimg: N*C*H*W\n",
    "        '''\n",
    "        img, w, h = sample['image'], sample['w'], sample['h']\n",
    "#         如果不是灰度图要改变维度\n",
    "        img_transposed = img.transpose((2, 0, 1))\n",
    "        return {'image':torch.from_numpy(img_transposed).float(), 'image_ori':sample['image_ori'], 'w' : w, 'h' : h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceLandmarksDataset():\n",
    "    def __init__(self, data, transforms= None, train_boarder= 224):\n",
    "        '''\n",
    "        :param lines: src_line\n",
    "        :param transform: data transform\n",
    "        '''\n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "        self.train_boarder = train_boarder\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.data.values[idx][0]\n",
    "        #打开图片\n",
    "        img = Image.open(img)\n",
    "        \n",
    "        #对lanmarks做变换\n",
    "        w = img.width\n",
    "        h = img.height\n",
    "        \n",
    "        sample = {'image':img, 'w' : w, 'h' : h}\n",
    "    \n",
    "        sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    '''\n",
    "    加载数据\n",
    "    '''\n",
    "    df = pd.read_csv(filepath)\n",
    "    tsfm = transforms.Compose([\n",
    "        Normalize(),\n",
    "        ToTensor()]\n",
    "    )\n",
    "    data_set = FaceLandmarksDataset(df, transforms= tsfm)\n",
    "    return data_set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T17:24:01.961132Z",
     "start_time": "2019-12-28T17:24:01.952355Z"
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    t1 = time.time()\n",
    "    path = 'data/test.csv'\n",
    "    predict_set = load_data(path)\n",
    "    predict_loader = torch.utils.data.DataLoader(predict_set, \n",
    "                                             batch_size= 1, \n",
    "                                             num_workers= 1, \n",
    "                                             pin_memory= False)\n",
    "    path_model = 'trained_models/detector_epoch_100.pt'\n",
    "    device = 'cuda'\n",
    "    model = Net_res().to(device)\n",
    "    model.load_state_dict(torch.load(path_model, map_location= device))\n",
    "    model.eval()\n",
    "    t2 = time.time()\n",
    "    landmarks = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(predict_loader):\n",
    "            if i % 100 == 0:\n",
    "                print('\\r','正在处理第{}张猫片'.format(i),end= '')\n",
    "            img = data['image'].to(device)\n",
    "            w = data['w'].item()\n",
    "            h = data['h'].item()\n",
    "            output_pts = model(img)\n",
    "            output_pts = output_pts[0].cpu().numpy()\n",
    "            output_pts[::2] = output_pts[::2]/224*w\n",
    "            output_pts[1::2] = output_pts[1::2]/224*h\n",
    "            landmarks.append(output_pts)\n",
    "    t3 = time.time()\n",
    "    print(t2 - t1)\n",
    "    print(t3 - t2)\n",
    "    return np.array(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-28T17:24:16.279534Z",
     "start_time": "2019-12-28T17:24:02.731792Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    landmarks = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(landmarks).to_csv('data/results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "path = 'data/test.csv'\n",
    "predict_set = load_data(path)\n",
    "t2 = time.time()\n",
    "print('load_data:', t2 - t1)\n",
    "predict_loader = torch.utils.data.DataLoader(predict_set, \n",
    "                                             batch_size= 1, \n",
    "                                             num_workers= 1, \n",
    "                                             pin_memory= False)\n",
    "t3 = time.time()\n",
    "print('data_loader:', t3 - t2)\n",
    "path_model = 'trained_models/detector_epoch_100.pt'\n",
    "device = 'cuda'\n",
    "model = Net_res().to(device)\n",
    "t4 = time.time()\n",
    "print('to_device:', t4 - t3)\n",
    "model.load_state_dict(torch.load(path_model, map_location= device))\n",
    "model.eval()\n",
    "idx = 25\n",
    "t5 = time.time()\n",
    "print('load_model:', t5 - t4)\n",
    "landmarks = []\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(predict_loader):\n",
    "        if i == idx:\n",
    "            img = data['image'].to(device)\n",
    "            w = data['w'].item()\n",
    "            h = data['h'].item()\n",
    "            img_ori = data['image_ori']\n",
    "            output_pts = model(img)\n",
    "            landmarks = output_pts[0].cpu().numpy()\n",
    "            \n",
    "            xs = landmarks[::2]/224*w\n",
    "            ys = landmarks[1::2]/224*h\n",
    "            plt.imshow(img_ori[0].numpy())\n",
    "            plt.scatter(xs,ys,s = 5, c = 'r', edgecolors= 'r')\n",
    "            plt.show()\n",
    "        elif i > idx:\n",
    "            break\n",
    "t6 = time.time()\n",
    "print('run:', t6 - t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "path = 'data/test.csv'\n",
    "predict_set = load_data(path)\n",
    "t2 = time.time()\n",
    "print('load_data:', t2 - t1)\n",
    "predict_loader = torch.utils.data.DataLoader(predict_set, \n",
    "                                             batch_size= 1, \n",
    "                                             num_workers= 0, \n",
    "                                             pin_memory= False)\n",
    "t3 = time.time()\n",
    "print('data_loader:', t3 - t2)\n",
    "path_model = 'trained_models/detector_epoch_100.pt'\n",
    "device = 'cuda'\n",
    "model = Net_res().to(device)\n",
    "t4 = time.time()\n",
    "print('to_device:', t4 - t3)\n",
    "model.load_state_dict(torch.load(path_model, map_location= device))\n",
    "model.eval()\n",
    "idx = 22\n",
    "t5 = time.time()\n",
    "print('load_model:', t5 - t4)\n",
    "landmarks = []\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(predict_loader):\n",
    "        if i == idx:\n",
    "            img = data['image'].to(device)\n",
    "            w = data['w'].item()\n",
    "            h = data['h'].item()\n",
    "            img_ori = data['image_ori']\n",
    "            output_pts = model(img)\n",
    "            landmarks = output_pts[0].cpu().numpy()\n",
    "            \n",
    "            xs = landmarks[::2]/224*w\n",
    "            ys = landmarks[1::2]/224*h\n",
    "            plt.imshow(img_ori[0].numpy())\n",
    "            plt.scatter(xs,ys,s = 5, c = 'r', edgecolors= 'r')\n",
    "            plt.show()\n",
    "        elif i > idx:\n",
    "            break\n",
    "t6 = time.time()\n",
    "print('run:', t6 - t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('data/test/0.jpg')\n",
    "\n",
    "img_resize = np.asarray(img.resize((224, 224),Image.BILINEAR))\n",
    "\n",
    "img_tensor = torch.from_numpy(img_resize.transpose((2, 0, 1))).float()\n",
    "\n",
    "path_model = 'trained_models_Copy2/detector_epoch_100.pt'\n",
    "model = Net_res()\n",
    "device = 'cpu'\n",
    "model.load_state_dict(torch.load(path_model, map_location= device))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(img_tensor.unsqueeze(0))\n",
    "\n",
    "xs = out[0,::2]\n",
    "ys = out[0,1::2]\n",
    "\n",
    "plt.imshow(img_resize)\n",
    "plt.scatter(xs,ys,s = 5, c = 'r', edgecolors= 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
